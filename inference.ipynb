{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1500c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T19:14:23.480743Z",
     "iopub.status.busy": "2026-01-06T19:14:23.480531Z",
     "iopub.status.idle": "2026-01-06T19:18:01.371999Z",
     "shell.execute_reply": "2026-01-06T19:18:01.371279Z"
    },
    "papermill": {
     "duration": 217.896766,
     "end_time": "2026-01-06T19:18:01.374471",
     "exception": false,
     "start_time": "2026-01-06T19:14:23.477705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cuda\n",
      "‚úÖ Model: /kaggle/input/new-training-model-ipynb/model_seed82.pth\n",
      "üìä Score range: 0.1408 ‚Üí 0.2931\n",
      "‚úÖ Done! submission_top10.csv saved.\n"
     ]
    }
   ],
   "source": [
    "#tta_inference_resnet_autoencoder.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"‚úÖ Using device:\", DEVICE)\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "TEST_DIR = \"/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos\"\n",
    "MODEL_PATH = None\n",
    "\n",
    "# Find model\n",
    "for root, _, files in os.walk(\"/kaggle/input\"):\n",
    "    for f in files:\n",
    "        if \"model_seed\" in f.lower() and f.endswith(\".pth\"):\n",
    "            MODEL_PATH = os.path.join(root, f)\n",
    "            break\n",
    "    if MODEL_PATH: break\n",
    "\n",
    "if not MODEL_PATH:\n",
    "    raise FileNotFoundError(\"‚ùå Model not found ‚Äî check data attachment\")\n",
    "\n",
    "# --- MODEL ---\n",
    "class ResNetAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=None)\n",
    "        self.encoder = nn.Sequential(*list(base.children())[:-2])\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 3, 2, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 3, 2, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        recon = self.decoder(feat)\n",
    "        return recon, feat\n",
    "\n",
    "# --- DATASET ---\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.samples = []\n",
    "        for vid in sorted(os.listdir(root_dir)):\n",
    "            vid_path = os.path.join(root_dir, vid)\n",
    "            if os.path.isdir(vid_path):\n",
    "                for f in sorted(os.listdir(vid_path)):\n",
    "                    if f.lower().endswith(('.jpg','.png')):\n",
    "                        frame_num = int(f.split('.')[0].split('_')[-1])\n",
    "                        self.samples.append((os.path.join(vid_path, f), int(vid), frame_num))\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, vid, frame = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))(img)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        return img, vid, frame\n",
    "\n",
    "# --- INFERENCE ---\n",
    "print(\"‚úÖ Model:\", MODEL_PATH)\n",
    "model = ResNetAutoEncoder()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)  # ‚Üê CRITICAL: Move to GPU\n",
    "model.eval()\n",
    "\n",
    "dataset = TestDataset(TEST_DIR)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# ===== CORRECT extract_features =====\n",
    "def extract_features(self, x):\n",
    "    x = self.encoder[0](x)   # conv1\n",
    "    x = self.encoder[1](x)   # bn1\n",
    "    x = self.encoder[2](x)   # relu\n",
    "    x = self.encoder[3](x)   # maxpool\n",
    "    x = self.encoder[4](x)   # layer1\n",
    "    x = self.encoder[5](x)   # layer2\n",
    "    f3 = self.encoder[6](x)  # layer3\n",
    "    f4 = self.encoder[7](f3) # layer4\n",
    "    return f3, f4\n",
    "\n",
    "if not hasattr(model, 'extract_features'):\n",
    "    model.extract_features = extract_features.__get__(model)\n",
    "\n",
    "# ===== INFERENCE LOOP (Full TTA + Noise-Favoring) =====\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for imgs, vids, frames in loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        batch_scores = []\n",
    "        \n",
    "        # üîπ FULL TTA (with vflip ‚Äî your last GOOD config)\n",
    "        tta_ops = [\n",
    "            lambda x: x,                          # identity\n",
    "            TF.hflip,                             # hflip\n",
    "            TF.vflip,                             # vflip\n",
    "            lambda x: TF.rotate(x, 180),         # rot180\n",
    "        ]\n",
    "        \n",
    "        for op in tta_ops:\n",
    "            a = op(imgs)\n",
    "            recon, _ = model(a)\n",
    "            \n",
    "            f3_a, f4_a = model.extract_features(a)\n",
    "            f3_r, f4_r = model.extract_features(recon)\n",
    "            \n",
    "            r_err = (a - recon).abs().mean([1, 2, 3])  # L1\n",
    "            err3 = ((f3_a - f3_r) ** 2).mean([1, 2, 3])\n",
    "            err4 = ((f4_a - f4_r) ** 2).mean([1, 2, 3])\n",
    "            f_err = 0.4 * err3 + 0.6 * err4  # conservative\n",
    "            \n",
    "            # ‚úÖ CRITICAL CHANGE: Noise-favoring balance\n",
    "            score = 0.795 * (r_err) + 0.205 * (f_err)  # ‚Üê +0.01 AP nudge\n",
    "            batch_scores.append(score)\n",
    "        \n",
    "        avg_score = torch.stack(batch_scores).mean(0)\n",
    "        final_score = avg_score ** 1.31  # Œ≥ = 1.28\n",
    "        \n",
    "        for v, f, s in zip(vids, frames, final_score):\n",
    "            results.append({\"video\": int(v), \"frame\": int(f), \"score\": float(s)})\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame(results)\n",
    "df[\"Id\"] = df.video.astype(str) + \"_\" + df.frame.astype(str)\n",
    "output_path = \"submission_top10.csv\"\n",
    "df[[\"Id\", \"score\"]].rename(columns={\"score\": \"Predicted\"}).to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"üìä Score range: {df['score'].min():.4f} ‚Üí {df['score'].max():.4f}\")\n",
    "print(f\"‚úÖ Done! {output_path} saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15067517,
     "sourceId": 126766,
     "sourceType": "competition"
    },
    {
     "sourceId": 289108337,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 224.995251,
   "end_time": "2026-01-06T19:18:04.636717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T19:14:19.641466",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
